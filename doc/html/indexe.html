<html>
<head>
<META http-equiv="Content-Type" content="text/html"; charset="utf-8">
<title>MetPX welcome</title>
</head>
<body>
<H1>MetPX - Meteorological Product eXchanger</H1>
<P>
$Date$
<p>
[<A HREF="indexf.html">fran&#231;ais</a>]
<P>
MetPX is a collection of tools created to support data acquisition, routing, and dissemination in a meteorological context.
There are two main applications in the MetPX suite: MetPX-sundew is the legacy WMO-GTS supporting message switching system.
<A HREF="#Sundew">MetPX-Sundew</a> transfers accepts, transforms, and delivers individual products.  
<A HREF="#Sarracenia">MetPX-Sarracenia</a> is the next generation tree replication system, currently under development, 
which transfers filtered, but largely un-modified directory trees of products on behalf of data sources.  
While Sarracenia leaves legacy compatibility behind in order to address more modern concerns, sundew remains 
necessary to interface to legacy systems.  

<P>
[<A HREF="#SaraDocumentation">Sarracenia Documentation</A>]
[<A HREF="#SundewDocumentation">Sundew Documentation</A>]
[<A HREF="#Download">Download</A>]
[<A HREF="http://sourceforge.net/project/showfiles.php?group_id=165061">Download</a>]
[<A HREF="#Source">Getting Source Code</A>]
[<A HREF="#Links">References &amp; Links</a>]
<br>
[ mailing-lists:   <A HREF="http://lists.sourceforge.net/lists/listinfo/metpx-devel"> metpx-devel.</a>, 
<A HREF="http://lists.sourceforge.net/lists/listinfo/metpx-commit"> metpx-commit.</a> ]
[ Main Project page:   <A HREF="http://www.sourceforge.net/projects/metpx"> Sourceforge </a> ]
<P>
<A NAME="Sarracenia"><H2>MetPX-Sarracenia</H2></a>
<P>
MetPX-Sarracenia is a data duplication or distribution engine that leverages existing standard technologies (web servers 
and the <A HREF="#AMQP">AMQP</a> brokers) to achieve real-time message delivery and end to end transparency in file 
transfers.  Whereas in Sundew, each switch is a standalone configuration which transforms data in complex ways, 
in sarracenia, the data sources establish a structure which is carried through any number of intervening switches until 
they arrive at a client.  The client can provide explicit acknowledgement that propagates back through the network to 
the source.  Whereas traditional file switching is a point-to-point affair where knowledge is only between each 
segment, in Sarracenia, information flows from end to end in both directions.
<P>
At it's heart, sarracenia exposes a tree of web accessible folders (WAF), using any standard HTTP server (tested with 
apache).  Weather applications are soft real-time, where data should be delivered as quickly as possible to the next 
hop, and minutes, perhaps seconds, count.  The standard web push technologies, ATOM, RSS, etc... are actually polling 
technologies that when used in low latency applications consume a great deal of bandwidth an overhead.  
For exactly these reasons, those standards stipulate a minimum polling interval of five minutes.   
Advanced Message Queueing Protocol (AMQP) messaging brings true push to notifications, and makes real-time 
sending far more efficient.
<P>
<IMG SRC="e-ddsr-components.gif">
<P>
Sources of data announce their products, switching systems pull the data using HTTP or SFTP onto their WAF trees, and 
then announce their trees for downstream clients.  When clients download data, they may write a log message back to 
the server.  Servers are configured to forward those client log messages back through the intervening servers back to 
the source.  The Source can see the entire path that the data took to get to each client.  With traditional switching 
applications, sources  only see that they delivered to the first hop in a chain. Beyond that first hop, routing is 
opaque, and tracing the path of data required assistance from administrators of each intervening system.  With 
Sarracenia's log forwarding, the switching network is completely transparent to the sources.  Diagnostics are 
vastly simplified.
<P>
For large files / high performance, files are segmented on ingest if they are sufficiently
large to make this worthwhile.  Each file can traverse the switch network independently,
and reassembly is only needed at end points.   A file of sufficient size will announce
the availability of several segments for transfer, multiple threads or transfer nodes
will pick up segments and transfer them.  The more segments available, the higher
the parallelism of the transfer.   In many cases, Sarracenia manages parallelism
and network usage without explicit user intervention.  As intervening switches
do not store and forward entire files, the maximum file size which can traverse
the network is maximized.
<P>
Where sundew supports a wide variety of file formats, protocols, and conventions specific to the real-time meteorology, 
sarracenia takes a step further away from specific applications and is a ruthlessly generic tree replication engine, 
which should allow it to be used in other domains.  The prototype client, dd_subscribe, in use since 2013, 
implements the consumer end of the switch's functions, and is the only component present in current packages.  The 
rest of MetPX-Sarracenia should be included in packages by the Fall of 2015.
<P>
Sarracenia is expected to be a far simpler application than sundew from every point of view: Operator, Developer, Analyst,
Data Sources, Data consumers.  Sarracenia imposes a single interface mechanism, but that single mechanism is completely portable
and generic.  It should run without issue on any modern platform (Linux, Windows, Mac)

<A NAME="SaraDocumentation"><h3>Sarracenia Documentation</h3></a>
<LI>Man Pages:
<UL>
<LI><A HREF="dd_subscribe.1.html">dd_subscribe.1</a> 
</UL>

<P>
<A NAME="WhyNotRSync"><H3>Why not just use Rsync?</h3></a>
There are a number of tree replication tools that are widely used, why invent another?  Rsync and other tools are
comparison based (dealing with a single Source and Destination)  Sarracenia, while it does not require or use multi-casting,
is oriented towards a delivery to multiple receivers.  Where rsync synchronization is typically done by walking a
large tree, that means that the synchronization interval is inherently limited to the frequency at which you can
do the file tree walks (in large trees, that can be a long time.) Each file tree walk reads the entire tree
in order to generate signatures, so supporting larger numbers of clients causes large overhead.  Sarracenia avoids 
file tree walks by having writers calculate the checksums once, and signal their activity directly to readers 
by messages, reducing overhead by orders of magnitude.  Lsync is a tool that leverages the INOTIFY features of 
Linux to achieve the same liveness, but the checksum management and log communication would need implementation, 
and it is obviously not portable. Doing this through the file system is thought to be cumbersome and less
general than explicit middleware message passing, which also handles the logs ins a straight-forward way.
<P>
One of the design goals of sarracenia is to be end-to-end.  Rsync is point-to-point, and does not support the "transitivity"
of transfers across multiple switching engines that is desired.  On the other hand, the first use case for Sarracenia 
is the distribution of new files.  Updates to files are not common, and so file deltas are not yet dealt with efficiently.  
ZSync is much closer in spirit to this use case, and Sarracenia may adopt zsync as a means of handling deltas, 
but it would likely place the signatures in the announcements.

<A NAME="Sundew"><H2>MetPX-Sundew</H2></a>
<P>
MetPX-sundew is a message switching system for use with <a href="http://www.wmo.int">World Meteorological Organization (WMO)</a> 
<A HREF="http://www.wmo.ch/pages/prog/www/TEM/XGTS/gts.html">Global Telecommunications System (GTS)</a> circuits based on TCP/IP.  The system is already production quality for a limited set of features and is in production 
use at the CMC as the core of our national switching infrastructure for bulletins, as well as file data (satellite, 
RADAR, numerical outputs, charts & imagery...) It is used to ingest from a NOAAPORT feed, as well as two GTS protocol 
links, feed several hundred clients in both socket and file based feeds, provide Canadian participation in 
<A HREF="http://www.unidata.ucar.edu/">Unidata</A> and <A HREF="http://tigge.ecmwf.int/">TIGGE</a> via a bridge to LDM,
as well as <A HREF="http://www.emc.ncep.noaa.gov/gmb/ens/NAEFS.html">NAEFS</a> via direct file transfer.
MetPX is unique in its ability to run fine-grained routing with low latency and high performance.  
Developed at the Canadian Meteorological Centre of <a href="http://www.ec.gc.ca">Environment 
Canada</a> for our own use.  Licensed under GPL for collaborative development, MetPX aims to be 
to meteorological switching what apache is to web serving.
<P>
Protocol support:
<UL>
<LI>AM (Canadian proprietary socket protocol) 
<LI>WMO (see manual 386 for the WMO TCP/IP socket protocol.)
<LI>FTP (for transport, no support for WMO naming yet (but trivial to add.))
<LI>SFTP (similar to FTP.)
<LI>AFTN/IP bridge (NavCanada version of AFTN running on IP networks.) 
<LI>AMQP bridge (open standard protocol, comes from the business messaging world.)
</UL>
<P>
features:
<UL>
<LI>detailed routing (in production with 30,000 distinct entries in the routing table.)
<LI>unified/similar for bulletins and files.
<LI>sub-second latency (with 28,000 routing entries.)
<LI>high speed routing and delivery. (was &gt;300 messages per second, but that was a year ago, and many features which might slow it down have been added, a re-test is in order.)
<LI>no message size limit.
<LI>message segmentation (for protocols such as AM &amp; WMO which have message length limits.)
<LI>duplicate suppression (on send.)
<LI>bulletin collections, NMC function for WMO. 
<LI>generalized filter mechanism.  (collections will be modified to fit this general mechanism.)
</UL>
</UL>
<P>
There are three modules in the project right now.  Modules of 
MetPX are named after species of plant which are endangered in 
Canada (see <A HREF="http://www.speciesatrisk.gc.ca"> Species at Risk </a> for more details.)
<UL>
<LI>sundew: the WMO switching component.
<LI>columbo: the web based monitoring component, for both sundew, and the older (not released) PDS.
<LI>stats: collection and display of statistics... (ok so it's not a flower...)
</UL>
<P>
<P>
Platform: we build packages for Debian Derived Linux (Debian Sarge, Etch. any Ubuntu will do).  
Any modern Linux should do. (stock 2.6 or 2.4 with many patches.)   Python &gt;2.3
<P>
Licensing: GPLv2

<A NAME="SundewDocumentation"><H3>Sundew Documentation</H3></a>
<UL>
<LI><A HREF="Guide.html">User's Guide</a>
<LI><A HREF="DevGuide.html">Contributor's Guide</a>
<LI>Man Pages:
<UL>
<LI><A HREF="px.1.html">px (main startup wrapper)</a>
<LI><A HREF="pxReceiver.1.html"> pxReceiver.1</a>
<LI><A HREF="pxSender.1.html">pxSender.1</a>
<LI><A HREF="pxTransceiver.1.html">pxTransceiver.1</a>
<LI><A HREF="pxFilter.1.html">pxFilter.1</a>
<LI><A HREF="pxRetransmit.1.html">pxRetransmit.1</a>
<LI><A HREF="pxRouting.conf.5.html">pxRouting.conf.5</a>
<LI><A HREF="pxRouting.7.html">pxRouting.7</a>
</UL>
</UL>

<A NAME="Download"><H3>Download Packages</H3>

<A HREF="http://sourceforge.net/project/showfiles.php?group_id=165061">Download</a>
<P>
Sundew is rather stable for now, current work is on improving the installation process by 
implementing Debian packages.  A package for the sundew module is available from
the sourceforge site, in either source or .deb form.  We hope to produce packages for 
columbo at some point.  



<A NAME="Source"><H3>Getting Source Code</H3>
<P>
Currently internal installations are done, one at a time, from source.  Development
is done on the trunk release.  When we install operationally, the process consists
of creating a branch, and running the branch on a staging system, and then implementing
on operational systems.  There are README and INSTALL files that can be used for 
installation of sundew.  One can follow those instructions to get an initial installed 
system.  
<P>
It is critical to install the cron cleanup jobs (mr-clean) since otherwise the 
server will slow down continuously over time until the system slows to a crawl.  If you 
Best bet is to subscribe to the mailing list and let us know what is stopping you from 
trying it out, it could inspire us to work on that bit faster to get some collaboration 
going.  
<P>
with those explanations, feel free to grab a snapshot can be obtained using subversion via:
<UL>
    svn co https://svn.code.sf.net/p/metpx/code/trunk
</UL>

Available for anonymous read-only access.  One can also download a stable release by doing an checkout by accessong the currently highest numbered branch.

<P>

<A NAME="AMQP"><h2>AMQP</h2></a>
AMQP is the Advanced Message Queuing Protocol, which emerged from the financial trading industry and has gradually 
matured.  Implementations first appeared in 2007, and there are now several open source ones.  AMQP implementations 
are not JMS plumbing.  JMS standardizes the API programmers use, but not the on the wire protocol.  So typically, one cannot 
exchange messages between people using different JMS providers.  AMQP standardizes for interoperability, and functions 
effectively as an interoperability shim for JMS, without being limited to Java.  AMQP is language neutral, and message 
neutral.  there are many deployments using python, C++, and ruby.  One could adapt WMO-GTS protocols very easily to 
function over AMQP.  JMS providers are very Java oriented.
<UL>
<LI><A HREF="http://www.amqp.org">www.amqp.org</a>  defining AMQP. 
<LI><A HREF="http://www.openamq.org">www.openamq.org</a> original GPL implementation from JPMorganChase
<LI><A HREF="http://www.rabbitmq.com">www.rabbitmq.com</a> another free implementation.  The one we use, and are happy with.
<LI><A HREF="http://cwiki.apache.org/qpid">Apache Qpid</a> yafi.
<LI><A HREF="http://activemq.apache.org/">Apache ActiveMQ</a> This is really a JMS provider with a bridge for AMQP.  They prefer their own openwire protocol. 
</UL>
Sarracenia relies heavily on the use of brokers and topic based exchanges, which were prominent in AMQP standards efforts prior
to version 1.0, at which point they were removed.  It is hoped that these concepts will be re-introduced at some point.  Until
that time, the application will rely on pre-1.0 standard message brokers, such as rabbitmq.

<A NAME="Links"><H2>References &amp; Links</H2>

Other, somewhat similar software, no endorsements or judgements should be taken from these links:
<UL>
<LI>Manual on the Global Telecommunications´ System: WMO Manual 386. The standard reference for this domain. (a likely stale copy is <A href="WMO-386.pdf">here.</a> try http://www.wmo.int for the latest version.
<LI><A HREF="http://www.unidata.ucar.edu/software/ldm">http://www.unidata.ucar.edu/software/ldm</a>  - Local Data Manager.  LDM includes a network protocol, and it fundamentally wishes to exchange with other LDM systems.  This package was instructive in interesting ways, in the early 2000's there was an effort called NLDM which layered meteorological messaging over a standard TCP/IP protocol.  That effort died, however, but the inspiration of keeping the domain (weather) separate from the transport layer (TCP/IP) was an important motivation for MetPX.
<LI><A HREF=http://www.dwd.de/AFD>http://www.dwd.de/AFD</a> - Automatic File Distributor - from the German Weather Service.  Routes files using the transport protocol of the user's choice.  Philosophically close to MetPX.
<LI><A HREF="http://www.corobor.com">http://www.corobor.com</a> - commercial WMO switch supplier. 
<LI><A HREF="http://www.netsys.co.za">http://www.netsys.co.za</a> - commercial WMO switch supplier.
<LI><A HREF="http://www.iblsoft.com">http://www.iblsoft.com</a> - commercial WMO switch supplier.
<LI>a variety of file transfer engines: Standard Networks Move IT DMZ, Softlink B-HUB & FEST, Globalscape EFT Server, Axway XFB, Primeur Spazio, Tumbleweed Secure File Transfer, Messageway.
<LI><A HREF="https://rsync.samba.org/">Rsync</a> provides fast incremental file transfer.
<LI><A HREF="https://code.google.com/p/lsyncd">Lsyncd</a> Live syncing (Mirror) Daemon.
<LI><A HREF="http://zsync.moria.org.uk">Zsync</a> Optimised rsync over HTTP.
</UL>
</body>
</html>
