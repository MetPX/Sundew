
Currently routing is a mix of direct routing for bulletins, and patterned routing for 
files.  There is weird processing for the various data types just because we needed it 
to work and thought they were special.  Taking a step back, we can see now how the 
processing is general.

Before version 1, the two methods need to be converged.  Both types of data need to have
transformations performed on the input before ingest, for data normalization, and after
to create derived products.

This should not change any of the processing done by the sockets  It should be the same
work being done now, just the order of and method of routine calls might be a bit different.
For files, it will be considerably different (but Better :-)

complexity of dictionary lookups in python is denoted as "A()" we have not investigated
what the algorithm for dictionary lookups is is it Log(n) or some constant factor (based
on a hashing algorithm... We know it is very good, but not the exact complexity.


Whys:
    Why Do we need to get PDS routing merged with bulletin routing?
     -- Even if we just use file receivers and client patterns, the fact that client patterns
	are used differently by different receivers will be extremely confusing in practice.
	It is only manageable now because the two contexts:  MetPX, and PDS are still separate.
	If we put both concepts within the same configuration, folks will get lost quickly.
	(as in: Hey, how come I am sending RADAR Volume scans over AMIS now?)

	Need for both groups to use the same words, concepts, and methods.  
        Broader number of people with same skills makes 24x7 coverage easier.

     -- MetPX routing latency is lower than PDS because we don't use the PDS algorithm.
        using the PDS algorithms will bring the latency back up, want 0 latency for files with
	hundreds of clients & thousands of patterns.

     -- The PDS people have been making their patterns more and more specific over time, converging
	on what the bulletin people already prefer.  Makes sense to move towards static routes and
        away from general patterns.
 
     -- Have many cases where the same client exists in both PDS and MetPX. Can have a single
	client configuration to encompass all the data we need to deliver to them.

     -- Why have two when you can have one! (clients & algorithms)


So without further ado ( The following is science fiction at the moment )



How It Ought to Work:


Product is received from source S:


0. Apply pre_ingest_filters

   apply any:
   pre_ingest_filter <string> 
   ?reception_filter -- alternate name

	-- pre_ingest_filters change data received, returns modified version.

   directives.  sample pre_ingest_filters:
   clean_WMO_bulletins( <data> )
	-- given actual file data, return cleaned stream.
	-- remove control characters, conver CR/NL to just NL, etc...   

   after applying pre_ingest_filters to the data.

   Why:
	Why Do we need this?
	   -- not sure, on all sockets there is this sort of processing.
	      maybe will make the individual receivers smaller with less
	      duplicated code, if we can abstract out the processing.
	      maybe not needed.

        Why Do we not write to a file? 
		-- We do not know the name to write to.



1. Determine Ingest name (except priority)
   ingest_namer <string>
   only one instance of this directive is permitted per source.  
   Based on 'ingest_namer' from etc/rx/S.conf 
	-- the value of ingest_namer is the name of a routine to create the ingest_name of the product.
	   ingest_namer is called with:
		-- name of file (nil if there isn'y any, as is the case with bulletins)
		-- patterns applicable (imask/emask entris in /etc/rx/S.conf, nil if there aren't any)
		-- 'extension' value  from etc/rx/S.conf
		the ingest_namer routine returns the name under which the file is to be ingested.
		if it returns an empty string, the data is to be dropped without being ingested.
		-- the one field not determined by the ingest namer is the priority.
	    
   sample values:

   bulletin_ingest_namer( filename, patterns, extension )
	-- will create a file name as a function of the bulletin header and extension.
           same as socket receivers today.  return file name.

   ambulletin_ingest_namer( filename, patterns, extension )
	-- will use collection_stations and other AM specific stuff to determine the correct name.

   file_ingest_namer( filename, patterns, extension )
	-- will create a file name as a function of ... whatever (depends on the application)
           returns the name. 
        -- 'imask' and 'emask' directives from  etc/rx/S.conf are applied against ingest name.
	   if it is excluded, then empty string is returned by routine.

   Why:
       Why Don't we create a file now? -- Because we do not know the priority, need routing lookup.	
       Why do we need 'namers'? -- To have similar routines for all data types, and not distinct
		routing algorithms for files vs. bulletins.  We don't know how to determine the
                name of an arbitrary product received, from receivers of types: AFTN, wmo, am, 
                bulletin-file,  single-file.  Assume they would all use the same algorithm
		with different namer routines.

   Once the ingest name is determined to be non-null, proceed to...




2. Find Routing Information (and Priority)
   The routing_namer is then called, with ingest name as the argument. 

   'routing_namer' from etc/rx/S.conf
	-- derives a routing name from the ingest name, and returns it.

   
        bulletin_routing_namer( ingest_filename ) 
	    will return: 'TTAAii CCCC' for a bulletin ... 


   the routing name is then looked up in the routing (aka... header2client) table:
        

	AACN01 CWAO:  Aviation Hydrology:3

	The priority is determined (3) and the ingest name is thus completed.
	and the client list determined also.

	if the routing name has no entry in the routing table, then apply:

	emask:<mask>
	imask:<mask>:<clients>:<priority>

	combinations from etc/header2client.conf

        ie.

	imask:AACN01 *:Aviation:3
	imask:* CWAO:Archives:4

   		-- select the highest priority among the matches, and catenate
		   the clients together.... result is equivalent to:

	AACN01 CWAO:Aviation Archives:3 

	The receiver then adds the evaluated entry to it's static routing table, effectively caching
        the routing information, for the next reception.

     Whys:
	Why don't we just use the imasks in all the clients?
	   -- because then we have two different routing methods, one for bulletins, one for files.
              want a single method for folks to learn and understand deeply.

	   -- Each of C clients can have Cm routing masks.  To route a single message will cost
			C * Cm  imask evaluations.
	      -- cost will increase quickly with the number of clients, and the number of masks. 
	      -- this will produce higher latency.
	          -- hmm... does caching results change this?... still O(A(Cm))*C... hmm...
                     more smaller tables... hmm... means short-circuiting 

	      the algorithm we want is the very close to the bulletin one, where routing with 
              the table is a lookup after the first one, so cost is:
			O(A(R)) 
		   R is the number of static entries in the routing table.
		   log R assumes the associative arrays in python are implemented efficiently.

	Why do we need a routing namer?
		-- because with file data, there is all sorts of crud to ignore, like unique id's
		   date stamps, and the like.  need to extract a name so that it does not vary over time
                   in order to lookup for routing.  
		-- if someone can figure out a generic way to extract a routing name, then we don't
                   need a routine. 

	Why don't we just put all the products statically in routing file (header2client.conf)? 
		-- because when we have file data, there are many, many different types. hard to know,
                   routing table will grow without bound, might work...

	Why do we need patterns in the routing table?
		-- because CMC bulletin people like specifying every header on the main switch, 
                   but for many other purposes, it is a bad fit:
		      -- non-main switching function... such as an rcp.
		      -- other country NMC's who knows what their taste is like.
		      -- for PDS, easier to use patterns.
   
        Why do we need to take the result of the pattern and add it to the static routing table?
		-- Because that way, you only pay for matching the masks the first time
		   you receive a particular routing name.  Afterwards, your are good for O(A(R)) 
	
	Why don't we do the same with the client patterns, and forget about global naming?
		-- because then we end up with two algorithms again.
		-- because we have to go through C routing tables, instead of just one, 
		   still more expensive than a single routing table:
		   O(A(Rc))*C
		


3. Ingest data into DB, and Route it.

	using the ingest_name, and the priority, link (or just write) the file in the rxq into the DB.

        Routing table, when initially read by receivers should have a ClientPatternsApplied flag for each entry.
        If this flag is True, then one has already applied to Clients' imask and emask entries, and removed 
	any destinations which were suppressed.

        if ClientPatternsApplied:
		send to the exising list of clients in the routing table.
        else:
	   for each C in the list of clients to be routed to:

	        look at imask and emask entries in etc/tx/C.conf
		if it passes the masks, then queue it in the appropriate txq directory.
                if it does not, then remove it from the routing table entry.
	   ClientPatternsApplied=True
	
	Why:
	   Why the new ClientPatternsApplied flag?
	   -- Faster... This way we cache results of applying client patterns.  
              Routing algorithm, after the first pass is O(A(n)) same as if there were no patterns.

	


4. Create Derived Products ( aka. apply reception post_ingest_filters. )
	- from etc/rx/S.conf

	  post_ingest_filter <pattern> <filter>
          post_filter ?

	  -- call <filter> when ingest_name matches <pattern>
	  -- a filter routine accepts the ingest_named file as an input, and performs a derivation
          operation.  
          -- Filters are not allowed to alter their input files.
	  -- returns a list of derived temporary files.

	-- sample filter:

	bulletin2uppercase(ingest_name)
	   -- creates a derived bulletin which is the same as the original, but in all uppercase.
	      returns the name of the uppercase bulletin in the DB.

        collective(ingest_name)
	   -- figures out if a bulletin is the subject of collection, triggers requisite processing.

	gif2imv6(ingest_name)
	   -- creates a derived imv6 format image file from the given gif in the rxq.
	   -- return the name of the derived files.

	for each derived product
	   Call step 1.  (recursive?)

	Why:
	   Why do we need derived products, aka 'transformations' aka. post_ingest_filters ?
		there are many cases where the receipt of a product should generate trivially derived products.
		examples of possible applications: 
		     upper-case bulletins could be produced when mixed case ones are received.
		     imagery in one format can be transformed into another.
		     bulletins should be examined on receipt for inclusion in collective ones.
	
	 	want to replace PDS + FileHandlingSystem which uses local clients and repeated passes through
	        the switch to accomplish essentially the same process in a much less obvious way.
		otherwise, retiring PDS will mean bringing over the same mechanisms (blech.)

	   Why don't we create a separate mechanism that does processing independently of reception?
	     -- don't need extra concepts/flows/processes.
	     -- transformations are expected to be short and sweet. delays minimal.
             -- for files (where transformations might be more involved), reception is done by 
                other servers anyways. data is already queued in the reception directory.
	
	   Why do we ingest the initial product before working on transformed ones?
	     -- every time a product is ready it is ingested ASAP, this is consistent regardless
		of whether it is an received product or the result of transformation.
		conceptual alternative would be to hold all products until all derivatives produced.
                that would delay transmission of original products.  Don't see why that is a good thing.
	

Other notes:
	
Once we get rid of pattern routing, we can reverse the meaning of the emask/imasks in clients (to default accept)
and thus make it's meaning consistent with their use elsewhere, and make them un-necessary in most cases.

