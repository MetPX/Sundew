"""
MetPX Copyright (C) 2004-2006  Environment Canada
MetPX comes with ABSOLUTELY NO WARRANTY; For details type see the file 
named COPYING in the root of the source directory tree.
"""
##################################################################################################
#  _____ _        _         _     _ _                          
# /  ___| |      | |       | |   (_) |                         
# \ `--.| |_ __ _| |_ ___  | |    _| |__  _ __ __ _ _ __ _   _ 
#  `--. \ __/ _` | __/ __| | |   | | '_ \| '__/ _` | '__| | | |
# /\__/ / || (_| | |_\__ \ | |___| | |_) | | | (_| | |  | |_| |
# \____/ \__\__,_|\__|___/ \_____/_|_.__/|_|  \__,_|_|   \__, |
#                                                         __/ |
#                                                        |___/ 
#                             
#
# Author: Nicholas Lemay
# Date  : June 27th 2006
#
#
###################################################################################################



GENERAL DESCRIPTION:
--------------------------------------------------------------------------------------------------- 

The stats library's main goal is to add the possibility to the existing px library to draw graphics of a
certain client based on stats collected from log files located remotely. This section thus contains all the
files needed to do this job. 



Files included in the stats library are :
------------------------------------

- ClientGraphicProducer.py  
- DirectoryStatsCollector.py 
- DirectoryFileCollector.py    
- FileStatsCollector.py 
- gzippickle.py
- MyDateLib.py
- pickleUpdater.py 
- StatsPlotter.py  

These library files are required by the stats library :

-DateLib.py : Many methods were added specifically for the stats library, 
              but are written so they could be reused for other applications
              down the road.    



File interaction : 
-------------------


                          
                          FileStatsCollector            StatsPlotter  
                                 /\                         /\
DirectoryFilecollector           |                          | 
                   /\            |                          |
                   |             |                          | 
                   |             |                          |
 gzippickle<--DirectoryStatscollector <-----------ClientGraphicProducer           
                     /\
                     | 
                     |
                pickleUpdater


--Note : x-->y means x uses y
                




File Descriptions 
----------------------------                
   

-ClientGraphicProducer.py : This files contains methods to be used when a user of this class wants to produce a graphic.
                            
                            It first takes the previously collected data, then adds up to it the data produced between the last collection and the time of the call.
                            
                            After that it calls StatsPlotter.py with the collected data and uses it to produce the graphic.



-DirectoryStatsCollector.py : Collects stats from all the files found in a directory.
                              
                              File names are gathered using DirectoryFileCollector.py.
                              
                              Data for each file is collected using the methods found in FileStatsCollector.   



-DirectoryFileCollector.py  :  This file is used to gather the list of file present in a specific directory.  
                               
                               This means all files wich are not directories and whose names don't 
                               start with '.' 
                               
                           --->When implemented, the method wich downloads the files from the machines into the directory may or may not be put here.<---


                           
-FileStatsCollector.py : This file contains all the methods needed to collect data from files and produce stats 
                         using said data.
                         
                         The general principle behind the data collection made here is that it's
                         always spit up into time buckets.
                          
                         Time buckets are a timespan selected by the user. Buckets
                         have the same width all throughout the total width the user has decided to collect data upon. 
                         
                         Data collected thus need a date of occurence so that it can be categorised.  
                         
                         Once data has been collected, stats will be created for each buckets. This means that every bucket will have it's own min, max, median and mean values.  



-gzippickle.py : This file contains save and load methods that permit users to serialise data using 
                 pythons pickling feature.
                  
                 This particular pickling implementaion uses gzip to zip files
                 before writing to disk.
                  
                 Data compression adds processing time for zipping and unzipping data, but it saves 
                 so much time on reading/writing to the disk that it becomes much faster overall. 
                 
                 cpickle is also used instead of pickle because it is a faster way of pickling data.  
                 
                 

-MyDateLib.py     : Temporary file wich contains data manipulation methods I have been working on. They probably should                      be addded to the regular DateLib.py once they are found to be usefull and reliable.   
                                                                           

-pickleUpdater.py : This program is the one to use to make automated data updates. Recommended usage is to call 
                    this program every hours to update the stored stats on a client. Calling this program at that rate
                    wil ensure that each update takes a reasonable amount of time and that graphics produced  



-StatsPlotter.py : This file contains the methods to plot a gnuplot graphic once the data has been
                   collected using the previously described files. This is very similar to the 
                   Plotter.py allready found in the library.  
                                 



REQUIREMENTS :
---------------------------------------------------------------------------------------------------

1- Library has to be able to read a specific format of log files.
   Format is as following : ??????????   

2- Library has to be able to gather files from remote locations.   
  
3- The user must be able to request a graphic on the fly and receive it within an acceptable time frame.
  ( < 40 sec )    



GUIDING PRINCIPLES
---------------------------------------------------------------------------------------------------

- Log files for a specific client are usually stored on many different machines.  

- Log file for a single day from a single machine can be quite large. ( average~ >30 megs)

- Gnuplot graphics, even with a lot of date are generated rather quickly. ( average~ <5 secs )

- Collecting a whole days worth of data and producing stats according to data collected is very long
  ( up to 5 minutes if a very large amount of data is processed. )

- Disk access is very slow. Anything that has to be loaded or saved on the disk slows down the entire
  process quite a lot.   




IMPLEMENTATION :
---------------------------------------------------------------------------------------------------


Remote file access:
--------------------

- Remotely located log files are transfered to the machine where the library is used.
  ( Should this rather be in DirectoryFilecollector?  thus far pickleUpdater.py contains a method called 
    def getfilesIntoDirectory( clientName, machines = "" ): wich fakes all the needed files being downloaded .  )

  
Data collection :
---------------------  

- To speed up data collection and stats production, past data collected is saved in a pickle file. 
  This way data for a specific timeframe only has to be collected and calculated once. This can save
  enormous amounts of time on graphic production if the timespan of the graphic asked by the user is
  of any importance. 
  
  FilesStatsCollector.py, DirecToryStatsCollector.py, pickleUpdater.py and gzipickle.py all contain
  methods to deal with pickled data and data pickling.
    

- Because of disk access times, data pickling can be quite slow. To speed it up gzipickle.py has been
  added to the library. gzippickle compresses data before pickling it and and unzips it before reading it.
  
  Even if these operations do take some time,  tests have shown that it still is a much 
  faster way of pickling large amounts of data than pickling and unpickling large, non-compressed data. 
  
  It's also been modified to use cpickle wich is somewhat faster than the regular pickle methods.    


- Data collection can be done on an automated basis using crontab to call pickleUpdater.
    

Graphic production
-------------------

- Graphics are produced using StatsPlotter.py. It's simply a modified version of Plotter.py
  wich was allready working and available in the library.
  
- Graphics can be produced by calling ??? in ClientGraphicProducer.py.
  
  The graphic drawn will have the timespan width specified by the user.
  
  If the now option is used, data will be collected up to the time of the last crontab call to
  pickleUpdater. In that case it will be drawn up to the minute at wich it was called and thus have
  the new data included.
  
  Otherwise, the graphic's data will not include data after the last crontab 
  call but will be drawn faster since no time will be spent on collecting and calculating new data.
      
  


Specifics
---------------------------------------------------------------------------------------------------

When using the pickleUpdater to make automatic updates, data collection will start where the last 
data Collection was made. If no pickling was made for that day, it will start at 00:00:00 of that 
day.   

Data pickling can only be done within the same day. If data needs to be collected in a previous
day, you need to specify the day in the call to pickleUpdater call. ***See usage for details.  


While using the higher level pickleUpdater and ClientGraphicProducer classes, time buckets and 
pickle files will be created on a much more rigid daily basis.

    - A FileStatsCollector instance will be created every day and contain time buckets starting at 
      00:00:00 that day and ending at 23:59:59. 
    
    - Pickle will dave each daily instance in a file named after the client's name and the date of 
      the pickle. 
      
      Every day, a new pickle will be created to contain the new FileStatscollector entry.     



Log Files 
---------------------------------------------------------------------------------------------------
The file wich contains the data we want to collect and calculate needs to have a specific format. 

This means that all file entries should have the following syntax : 

....to be completed when exact log format is chosen....



Pickle Files :
---------------------------------------------------------------------------------------------------


PICKLED-TIMES :
---------------

This is the only file created to contain all the last pickleUpdates times fro each of the different 
clients. This file is save in a regular non-compresses pickle format. This is done so that a user 
could easily modify a certain client's date if needed.




SERVER NAME-PICKLE-2006-07-1
------------------------------ 

These file are created as to save the data collected for the period covering the day specified 
in the file's name.  This file contains a FileStatsCollector instance containing all the data
collected for that day compressed using gzippickle.py .
 
These files will be grouped in a folder 
named PICKLES(?). This folder will contain many subfolder, all of wich named after a certain clients 
name. Theses folder will contain all the pickle files of that client.  



USAGE:
---------------------------------------------------------------------------------------------------

To be completed when usage is final.... Current picklUpdater usage is : 


Options:
 
    - With -c|--clients you can specify the clients names on wich you want to collect data. 
    - With -d|--date you can specify the time of the update.( Usefull for past days and testing. )
    - With -i|--interval you can specify interval in minutes at wich data is collected. 
    - With -m|--machines you can specify on wich machine we must try to download log files.
    - With -n|--now you can specify that data must be collected right up to the minute of the call. 
    - With -t|--types you can specify what data types need to be collected

Defaults :

- Default Client name does not exist.
- Default Date of update is current system time.  
- Default interval is 1 minute. 
- Default machines value is the entire list of existing machines.  
- Default Now value is False.
- Default Types value is latency.
        
      
WARNING: - Client name MUST be specified,no default client exists. 
         - Interval is set by default to 1 minute. If data pickle here is to be used with 
           ClientGraphicProducer, default value will need to be used since current version only 
           supports 1 minute long buckets. 
          
            
Ex1: python pickleUpdater                                    --> All default values will be used. Not recommended.  
Ex2: python pickleUpdater -c satnet                          --> All default values, for client satnet. 
Ex3: python pickleUpdater -c satnet -d '2006-06-30 05:15:00' --> Client satnet, Date of call 2006-06-30 05:15:00

 

INPUT VALIDATION
---------------------------------------------------------------------------------------------------

Date option MUST be of the ISO format meaning a date like this : '2006-06-30 05:15:00'.
-i --intervall must be an integer value greater than 0.
-n --now option needs no value. 


Critical errors
---------------------------------------------------------------------------------------------------
To be completed....    
       

TODO list 
----------------------------------------------------------------------------------------------------

-Decide wheteher or not bucket size should be choosen by user. Graphics wich span over numerous day
  with different buckets widths might be hard to handle.

-Fix potential bug where pickled times is updated before program is finished. This might cause a conflict
 if application fails before it actually did collect the data.-***Done 
  
-Find the log file format. Modify findFirstInterestingLine, findValue(line) and while loops according 
 to new file format                 

-Modify module that gets files into a directory so that it actually downloads the files.
    -Add everything wich relates to the machine option.
    
-Add part that creates PICKLE directory and creates each subfolders for all the clients.***Done 
  

-Try and find another way to find if files is valid. Grep sometimes results in broken pipe errors...
 If no better way is found, find a way to trap broken pipe error   

-Add fields to the graphics : # of files with over 15 sec of latency. %of files with over 15 sec of latency.***Done

-Find a folder system to store created pics + Automated cleanup system ?

-Speed up graphic creation by not collecting data since last cron job if no necessary. File verification seems like its 
slowing down the whole process***done
