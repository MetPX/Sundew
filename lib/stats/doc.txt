"""
MetPX Copyright (C) 2004-2006  Environment Canada
MetPX comes with ABSOLUTELY NO WARRANTY; For details type see the file 
named COPYING in the root of the source directory tree.
"""
##################################################################################################
#  _____ _        _         _     _ _                          
# /  ___| |      | |       | |   (_) |                         
# \ `--.| |_ __ _| |_ ___  | |    _| |__  _ __ __ _ _ __ _   _ 
#  `--. \ __/ _` | __/ __| | |   | | '_ \| '__/ _` | '__| | | |
# /\__/ / || (_| | |_\__ \ | |___| | |_) | | | (_| | |  | |_| |
# \____/ \__\__,_|\__|___/ \_____/_|_.__/|_|  \__,_|_|   \__, |
#                                                         __/ |
#                                                        |___/ 
#                             
#
# Author        : Nicholas Lemay
# Last Update   : November 18th 2006
#
#
###################################################################################################


About this document :
---------------------------------------------------------------------------------------------------

This file was written for anyone using the stats library who might be interested in it's inner 
workings. Developers and end-users alike will be able to understand the principles behind the 
development of this library. Special care was given to describing the requirements and observations
that were made during development as to guide someone who might be interested in modifying this 
library. Hopefully this will explain why things were done a certain way and keep the developper 
from doing the same errors that were made during initial development.   


Stats library overview :
--------------------------------------------------------------------------------------------------- 

The stats library's main goal is to manage stats regarding different clients/sources and to add the 
possibility to to draw graphics based on said stats.

The graphic's data is based on the data calculated from log files located remotely and saved into
pickle files.



DEVELOPMENT REQUIREMENTS :
---------------------------------------------------------------------------------------------------

- Library has to be able to gather log files from remote locations( machines ). 

- Library has to be able to read a specific format of log files.

- Library must allow user to collect data of log files wich are constantly growing. 

- Library must permit data collection of log files that contain information about the same source/client but
  that comes numerous source machines. Each are remotely located. 
    
- Library must have a way to save data collected. Data needs to be stored in an efficiant manner
  so that we can keep data for up to 10 years. 

- Library must be able to collect the following data : errors, bytecount and latency.

- Library must have a way to save wich product type is associated with each line collected.  

- Data collection and saving must be done as quickly as possible. This must also be done 
  without affecting the machine on wich it is being run too much. 

- Library must be able to produce graphics of the .png format based on the saved data.

- Library must be able to display such graphic to a user within an acceptable time frame.( < 40 sec )    
  
- Library must allow user to specify the following options for data collection and graphics production :
  machine name, current time, source/client name, file type.

- Library must be built in such a way that all the above action can be done on an automated basis.
  
- Library must have mechanisms that allow data collection to be reverted in case errors are found.
 


GUIDING PRINCIPLES
---------------------------------------------------------------------------------------------------

- Log files for a specific source/client are often stored on many different machines.  

- Log file for a single day from a single machine can be quite large. ( average~ >30 megs )

- Log file names aren't reliable. Even if a file has a certain date in it's name it doesn't
  necessarily mean it will contain data for that day. File content still need to be investigated to 
  make sure it does or doesn't contain usefull info.   

- Having every machine perform the collection of the data found in the files that are present
  in it's own space makes the application must more scalable in the event that more machines and 
  or sources/clients are to be added. 
  
- Collecting a whole days worth of data and producing stats according to data collected is very
  long therefore more frequent data collection should be made. Hourly collection seems optimal for 
  logical and performance reasons.  
  
- Disk access is very slow. Anything that has to be loaded or saved on the disk slows down the entire
  process quite a lot. 
  
- Because of the preceding, we've found out that using a single daily file would make it impossible to 
  meet the above requirements.
  
- Even with optimization, on a users machine the time taken to pickle a single hour of data using a
  single pickle file every day went from three seconds( maximum ) for the first few hours to almost
  10 seconds( maximum ) for the last hours of the day.  
  
- Pickling done during the final hour of the day on a machine containing 150 sources/clients would mean 
  roughly 150 * 10 sec = 1500 sec( 1500 /60 sec = 25 minutes )Wich was too much time dedicated to 
  collecting data.
  
- Saving pickled data into hourly files makes sure that time used for pickling remains stable 
  throughout the day. It also makes the total amount of time much more acceptable. 
  
  On a normal machine it would mean ~3 sec * 150 = 450 450/60 = 7.5 minutes( worst case scenario )
  
- On more performant dev machines where the app is being tested, it takes a maximum of a second to
  update a single source/client wich would mean 150 seconds or 2.5 minutes.
 
  Currently with tests on pds3-dev,and pds4-dev wich has 70 active sources/clients it takes less than 15 secs
  to create all the hourly pickles for the 70 sources/clients.          

- These test machine all have numerous processors. Since data collection times have been brought down
  to very quick times it has been decided not to launch any more process to try and speed up the
  collecting since it might slow down other applications for a minimal performance boost. 

- Gnuplot graphics are generated rather quickly but still take a few seconds each( < 5seconds ). 

- Therefore it has been decided that multi-processing would be usefull when producing graphics.
  Number of simultaneously ran process' can be modified as to not increase machine load too much.

- For the same reasons multi-processing has been implemented on transfers from pickle files to rrd
  databases.



IMPLEMENTATION :
---------------------------------------------------------------------------------------------------


Remote file handling ( rsync )
----------------------
For testing purposes, data collection was not made directly on the machines containing the log
files. Therefore log files were downloaded to another machine using rsync. rsync has been chosen
since it will only download part of the files that are missing when files are allready found on 
destination machine. It also offers a --delete option wich deletes files on the destination machine 
wich are no longer present on the source machine. This allows for a picture perfect mirror of the 
source, while saving us the trouble of implementing an outdated-file purging mechanisn.   

The following line is usually used to get and exact copy of the log folder of a certain machine
into the desired machines.

rsync -avzr --delete-before  -e ssh pds@pxatx:/apps/px/log/  LOCAL_PATH_TO_LOGFILES >>/dev/null 2>&1 

The --delete-before option will delete from the local folder any file that is no longer present 
in the folder we want to mirror. SSH option will allow for an ssh connection to be made between
machines.

The avzr are standard rsync option meaning that download should be recursive(r), verbose(v),
compressed(z) and archive(a).

File synchronisation between pickle producing machines and graphic producing machines
( pickleSynchroniser.py ) and synchronisation of running sources/clients between machines also use rsync
connections.
 

Data collection :
---------------------  

- To speed up data collection and stats production, past data collected is saved in a pickle file. 
  This way data for a specific timeframe only has to be collected and calculated once. This can
  save enormous amounts of time on graphic production if the timespan of the graphic asked by the 
  user is of any importance. 
  
  FilesStatsCollector.py, DirecToryStatsCollector.py, pickleUpdater.py and gzipickle.py all contain
  methods to deal with data pickling and pickled data.
     
- Because of disk access times, data pickling can be rather slow. To speed it up cpickle has been
  added to the library. cpickle is a c based implementation of pickle that has much faster methods
  than the usual pickle.
  
- Data collection can be done on an automated basis using crontab to call pickleUpdater.

- Data colection can be made on growing files. This is true as long as the top of the file remains
  intact and that data is only appended at the end of the log files. If top of the file is modified,
  the saved positioning of the file will be corrupted and reading the file will probably produce errors.  

- File positioning of the last read file is saved for every sources/clients in the 
  /apps/px/stats/PICKLED_FILE_POSITIONS pickle file.
  
- By default all data types are collected. This is done so that there will be no problem if a user wants
  to produce any kind of graphic for a certain source/client.

- User can specify wich data types he wants collected but that will limit user choices for graphics.  
  

Gathering pickled files:
------------------------

- Remotely located pickle files are to be transfered to the machine where the graphics are to 
  be created. see pickleSynchroniser.py for details.           


Archiving the pickled data.
-------------------------------

The data contained in pickled files takes up a lot of space and contains a lot of data
that is usefull for short amount of time only, and that can be discarded when viewing 
data for wide amounts of time. We have therefore decided to archive our pickled data 
by transferring it into rrd databases.

Such databases have a fixed size so they are very space efficient when using data 
that spans over a large amount of time and that precise information is not needed. 
rrdTool also offers to efficiently plot graphics(rrdgraph) based on the data contained in an rrd.   

To transfer data into rrd databases( transferPickleToRRD.py ) and plot graphics with rrdgraph
( generateRRDGraphics.py) you will need to have the rrdtool python library installed on your
machine.

See rrdToolDoc.txt for more details on rrdTool.   


Graphic production
-------------------

- Graphics with a short timespan are to be produced using StatsPlotter.py. 
  It's simply a modified version of Plotter.py wich was allready working and
  available in the library. This file uses gnuplot to generate the graphic
  so the gnuplot library is required here.    
     
- Graphics with longer timespans can be drawn using generateRRDGraphics.py
  This files uses rrdtool rrdgraph program to draw ints graphics. These graphics contain 
  less detail and can only display one graphic per image but since our rrd database will
  contain data for up to the last ten years it will allow users to easily produce daily, weekly,
  monthly and yearly graphics.
    
- It is possible to produce graphics for each data type collected. This means latency, bytecount 
  and errors.  

- It is impossible to create a graphic on a data type wich was not previously collected. 
  This is why by default all types are collected and pickled. This allows users to have access 
  to every data type possible. 



Dealing with remote machines
-----------------------------
- To make the application more scalable in terms of a possible growing number of machines it was 
  decided that every machines would do it's own data pickling using pickleUpdater. 

- Some sources/clients have their data stored on different machines. pickleMerging.py has been introduced
  in the library to make merging of different machines pickles possible.  

- Since the graphic producing machine is at the heart of the library, it is this machine that will
  launch all the updates on the remote machines containing the log files. 
  
- remotely executed commands using ssh need to be added in the crontab of the graphic producing 
  machine.
  ***See howTo.txt to see how too add line.     

- The graphic producing machine also needed all the pickles created remotely to generate graphics.
  This prompted the implementation of a rsync system (pickleSynchroniser.py) that allows pickled 
  data found on numerous machines to be brought back in a single folder of a specific machine
  if needed.

- The graphic machine has no way of knowing if it is using the right version of the pickle files. 
  Therefore we have implemented a file version checking program that uses the time of creation of the 
  pickle files to see if a newer version has appeared on the pickleCreation machine. If so the 
  graphic generation program will use the new file next time a graphic using this pickle file is asked
  for by a user.  



List of files included in the stats library are :
--------------------------------------------------------------
- ClientGraphicProducer.py  
- ClientStatsPickler.py 
- cpickleWrapper.py
- DirectoryFileCollector.py    
- FileStatsCollector.py 
- generateGraphics.py
- generateRRDGraphics.py
- generateAllGraphsForServer.py
- MyDateLib.py
- pickleCleaner.py 
- pickleMerging.py
- pickleUpdater.py 
- StatsPlotter.py  
- pickleSynchroniser.py
- pickleViewer.py
- pickledTimesViewer.py
- PickleVersionChecker.py
- transferPickleToRRD.py


These library files are required by the stats library :
-------------------------------------------------------------------

-DateLib.py : Many methods were added specifically for the stats library, 
              but are written so they could be reused for other applications
              down the road.    

-Gnuplot library : Folder named Gnuplot containing the gnuplot library should be found in 
                   the imported libs folder of the library.                
                   
-backwardReader.py : Methods here are used to read a file backwards.
              
-PXPaths           : List of paths to be used in the px library. 


Environment variables :
---------------------------------------
The following environment variable needs to be set in order for the file interaction
to work.

PYTHONPATH=:/apps/px/lib:/apps/px/lib/importedLibs:/apps/px/lib/stats/

It should be set in the .profile(or equivalent) of machines where programs are to be run locally.

On hosts of remotely executed commands, it should be set in the $HOME/.ssh/environment file.

Further more, the PermitUserEnvironment parameter must be set to yes in the /etc/ssh/sshd_config
file or else the environment file will be ignored by ssh.

Finally, the same variable needs to be set in the crontab file if crontabs are to be used on 
a machine. Use crontab -e and add the line prior to the line containing the command that relates to
one of the programs of the library.



File interaction : 
-------------------

                                   PickleVersionChecker
                                              /\
                          FileStatsCollector  |          StatsPlotter  
                                 /\      /\   |             /\
DirectoryFilecollector           |       |    |             | 
                   /\            |   pickleMerging          |
                   |             |                /\        | 
                   |             |                |         |
 gzippickle<--ClientStatsPickler<-----------ClientGraphicProducer           
              /\    /\    /\                                  /\
               |    |     |                                   |
               |    |     |                                   | 
transferPickleToRRD |  pickleUpdater                      generateGraphics
                    |                                          /\         
                    |                                          |
     generateRRDGraphics                        generateAllGraphsForServer                
                
                
                
--Note : x-->y means x uses y            

---------------------------------------------------------------------------------------------------

Quick File Overview 
----------------------------                
   
-backwardReader.py : Contains two usefull methods for this library and possibly for other.
                     
                     -Has a readlineBackwards method that is similar to readline but that reads
                      a file from the bottom up. 
                     
                     -Has a tail method that is similar to the tail used in linux but in pure python. 
                     
                     
-ClientGraphicProducer.py : This file contains methods to be used when a user of this class wants 
                            to produce a graphic.
                            
                            It first takes the previously collected data, then adds up the data 
                            produced between the last collection and the time of the call.
                            
                            After that it calls StatsPlotter.py with the collected data and uses it
                            to produce the graphic.


                            
-ClientStatsPickler.py :      Collects stats from all the files needed to cover a certain timespace.
                              
                              File names are gathered using DirectoryFileCollector.py.
                              
                              Data for each file is collected using the methods found in
                              FileStatsCollector.   
                    
                              Introduces the pickling principle to the library. 
                              
                              
-cpickleWrapper.py : very small wrapper that allows for directory creation if the path to the 
                     file name saved does not exist.
                     
                     Also handles exceptions when trying to open a file that does not exist.
                 
                         
-DirectoryFileCollector.py  :  This file is used to gather all the interesting files present in 
                               a specific directory.  
                               
                               Search is based on fileType, client's name and timespan for wich 
                               we need data.
                               
                               
-FileStatsCollector.py : This file contains all the methods needed to collect data from files and
                         produce stats using said data.
                         
                         The general principle behind the data collection made here is that it's
                         always spit up into entries /apps/px/lib/stats/generateAllGraphsForServer.py
                          -m 'pds5,pds6' -c  -l 'pds,pds'of a certain length.

                          
                         File entries are of a timespan selected by the user. Entries will
                         have the same width all throughout the total width the user has decided 
                         to collect data upon.                        
                         Once data has been collected, stats will be created for each buckets. 
                         This means that every bucket will have it's own min, max, median and 
                         mean values.  
                                                  
-generateGraphics       :  This file offers to the user a command line interface so he can easily
                           use the functionalities offered by ClientGraphicProducer.py. 

                           
-generateAllGraphsForServer : Serves as a wrapper for generate graphics by adding the possibility
                              to generate a graphic for each and every client found on a specified 
                              server. Very usefull in cron jobs to produce timely graphics.                                                     
                               
-generateRRDGraphics.py    : RRD implementation of generateGraphics/generateAllGraphsForServer that
                             is made different by using rrd databases as data sources and rrdgraph 
                             to produce graphics instead of gnuplot.
                             
                             Otherwise it is similar to generateGraphics and generateAllGraphsForServer
                             as it allow to create graphs from command line and for as many sources/clients
                             as desired.                          
                                     
                     
-MyDateLib.py     : Temporary file wich contains date manipulation methods I have been working on.
                    They probably should be addded to the regular DateLib.py once they are found to 
                    be usefull and reliable.   
                    

                                                       
-pickleMerging.py : This file contains the methods needed to combine data found in different pickle
                    files that are covering the same time period. Example : Data that comes from the
                    same source/client but from different machines.
                    
                    It also has the possibility to merge pickles covering a certain time frame. For
                    example you could merge data coming from 12 pickles containing an hour's worth 
                    of data each into a single pickle file covering the entire 12 hours. 
                    
                    This will be very usefull if some pickles for the same source/client are produced 
                    on different machines and some operation concerning all the data must be done on
                    a cpecific machine.
                    Ex : See Clientgraphicproducer...               
                                                   
    
-pickledTimesViewer.py: Allows users to see clearly the content of the pickled times file. 
                         Might be found usefull for debuging purpouses. 
                         
-pickleSynchroniser : Implementation of an rsync system. Allos a machine to synchronise the content
                      of it's pickle folder with the one located on a remote machine. 
                      
-pickleUpdater.py : This program is the one to be used to make automated data updates.
                    Recommended usage is to call this program every hours to create the hourly 
                    pickles the contain stats on a source/client.     
                                             
-PickleVersionChecker.py  : This class is used in the library to keep track of the changes made
                            within files.
                            
                            Since pickles files are synchronised on grpahic machine they are prone
                            to change without the local machine knowing.           

                                                    
-pickleViewer.py : Allows user to view the content of a cpickle file that contains a
                   FileStatsCollector instance. Output can be directed to a text file if wanted. 
                    
                    Very usefull for debugging, making sure data collected is stored at the right
                    place,and comparing it to the graphics produced to see if there are any
                    differences. 

-StatsPlotter.py : This file contains the methods to plot a gnuplot graphic once the data has been
                   collected using the previously described files. This is very similar to the 
                   Plotter.py allready found in the library.  

-transferPickleToRRD : This files contains all the methods needed to transfer pickled data
                       that was saved using pickleUpdater.py into an rrd database.
                       In turn, the rrd database can be used to plot graphics using rrdTool.            
                    
         

File system 
---------------------------------------------------------------------------------------------------

Pickle Files :
---------------

/apps/px/stats/PICKLED-TIMES :
-------------------------------
This is the only file created to contain all the last pickleUpdates times from each of the different 
sources/clients. This file is save in a regular non-compresses pickle format. This is done so that
a user could easily modify a certain client's date if needed.


/apps/px/stats/PICKLED_FILE_POSITIONS:
---------------------------------------
Contains a list of positions stating where we last read a file for a specific source/client. 


/apps/px/stats/FILE_VERSIONS:
------------------------------
Contains a list of file update time saved by PickleVersionChecker. See PickleVersionChecker.py
for details.


/apps/px/stats/pickles/clientName/YYYYMMDD/fileType/machineName_hh
-------------------------------------------------------------------- 

These file are created to save the data collected for the period covering the hour specified 
in the file's name.  This file contains a FileStatsCollector instance containing all the data
collected for that hour saved with cpickleWrapper.py.
 
These files will be grouped in a folder named pickles. This folder will contain many subfolder,
all of wich named after a certain source/client name. Theses folder will contain all the pickle 
files of that source/client.  
             
             -----
Example :   |Stats|
             -----
               |
            ------------
            | PICKLES  |
            ------------
          /            \
         /              \
       ------          ----------
      | pds5 |        |satnet-ice|
       ------          ----------
       /                    \
      /                      \
  ----------           -------------   
 | 20060712 |         |  20060712   |      
  ----------           -------------
      /                       \
     /                         \
  ------                     ------
 |  rx  |                   |  tx  |
  ------                     ------  
    /                           \
   /                             \
lvs1-dev_17                   lvs1-dev_17
   

.../stats/graphs/clientName/fileType_clientName_YYYYMMDD_HH:MM:SS_dataTypes_XXhours_on_server.png
-------------------------------------------------------------------------------------------------
The files are created everytime a graphic is asked for by a user. This will be the png image 
containing all the graphics asked for by the user during his resquest.  It will contain graphs
for each of the data types asked for as many sources/clients as specified. 

These files will be grouped in a folder named graphs. This folder will contain many subfolder,
all of wich named after a certain source/client name. Theses folder will contain all the image 
files of that client.


               -----
Example :     |stats|
               -----
                 |
            ------------
            | graphs   |
            ------------
          /            
         /              
       ------         
      | amis |        
       ------          
       /                    
      /                      
tx_amis_20060801_05:00:00_'latency','errors','bytecount'_12hours_on_lvs1-dev.png
   



Databases
----------

/apps/px/stats/databases/type/client_machinename
---------------------------------------------------
These files are created when user asks for data to be transferred from pickle files
to an rrd database. Type will be either bytecount, errors, filecount, filesOverMaxLatency or latency.
      
               -----
Example :     |stats|
               -----
                 |
            ------------
            | databases |
            ------------
          /            
         /              
       --------         
      | errors |        
       --------          
        /                    
       /
ws-fortsimpson_pds5pds6


/apps/px/stats/DATABASE-UPDATES/fileType/client_machineName
------------------------------------------------------------
These files are pickle files containing the time of the last database update of a certain
client/database 


Important notes ( Specifics )
---------------------------------------------------------------------------------------------------

When using the pickleUpdater to make automatic updates, data collection will start where the last 
data Collection was made. If no pickling at all was made for that source/client, it will start at xx:00:00
of that the hour specified.   

Data pickling a source/client thats not listed in PICKLED-TIMES can only be done within the same hour.
If data needs to be collected in a previous hour, you need to specify the day in the call to pickleUpdater
call. ***See usage for details.  

Data pickling can otherwise be done over numerous days. This means that if no pickling occured for a few 
days for some reason, pickling can be resumed like nothing happened although first pickle update will be 
quite long. 

While using the higher level pickleUpdater and ClientGraphicProducer classes, time buckets and 
pickle files will be created on a much more rigid daily basis.

    - A FileStatsCollector instance will be created every hour and contain time buckets starting at 
      xx:00:00 that hour and ending at xx:59:59. 
    
    - Pickle will dave each daily instance in a file named after the source/client name and the date of 
      the pickle. 
      
    - Every hour, a new pickle will be created to contain the new FileStatscollector entry.     


Graphics cannot be produced for a data type wich was not previously collected for that source/client. 

If need be, PICKLED-TIMES can be modified so that library thinks last pickle update occured at a
different time than was written.           
        

USAGE:
---------------------------------------------------------------------------------------------------

1- See the howTo.txt file contained in this folder.
2- Most files whos name start with a lower case letter can be executed with a -h option to get usage.
3- All .py files are rather heavily commented within their code.


Todo, bugs etc....
---------------------------------------------------------------------------------------------------
To be completed...    
       





 

 
 